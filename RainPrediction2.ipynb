{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199e789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the given features: No\n",
      "Logistic Regression Accuracy: 0.8179568266190018\n",
      "Decision Tree Accuracy: 0.7554310463357624\n",
      "Random Forest Accuracy: 0.8256565378798295\n",
      "\n",
      "Machine Learning Model Comparison:\n",
      "1. Logistic Regression: \n",
      "- Accuracy: 0.818\n",
      "- Precision: 0.673\n",
      "- Recall: 0.341\n",
      "- F1 Score: 0.453\n",
      "2. Decision Tree:\n",
      "- Accuracy: 0.755\n",
      "- Precision: 0.447\n",
      "- Recall: 0.456\n",
      "- F1 Score: 0.452\n",
      "3. Random Forest:\n",
      "- Accuracy: 0.826\n",
      "- Precision: 0.675\n",
      "- Recall: 0.404\n",
      "- F1 Score: 0.506\n",
      "\n",
      "Model saved successfully as 'logreg.joblib' in the './models' directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\K R Sudarshan\\Python\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Section 1: Preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('weatherAUS.csv')\n",
    "\n",
    "# Drop columns with too many missing values\n",
    "df.drop(['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the Date column as it's not needed for the model\n",
    "df.drop(['Date'], axis=1, inplace=True)\n",
    "\n",
    "# Handle missing values using mean for numerical columns and most frequent for categorical columns\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply imputers\n",
    "df[numerical_cols] = num_imputer.fit_transform(df[numerical_cols])\n",
    "df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Ensure the target column exists and is correctly encoded if necessary\n",
    "if 'RainTomorrow' in df.columns:\n",
    "    df['RainTomorrow'] = df['RainTomorrow'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# One-hot encode all categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "if not categorical_cols.empty:\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Split the dataset\n",
    "X = df.drop(['RainTomorrow'], axis=1)\n",
    "y = df['RainTomorrow']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Section 2: PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Section 3: Simple Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_pca, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test_pca)\n",
    "log_reg_acc = accuracy_score(y_test, y_pred_log_reg)\n",
    "lrp = precision_score(y_test, y_pred_log_reg)\n",
    "lrf1 = f1_score(y_test, y_pred_log_reg)\n",
    "lrr = recall_score(y_test, y_pred_log_reg)\n",
    "\n",
    "# Decision Tree\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train_pca, y_train)\n",
    "y_pred_tree = tree.predict(X_test_pca)\n",
    "tree_acc = accuracy_score(y_test, y_pred_tree)\n",
    "treep = precision_score(y_test, y_pred_tree)\n",
    "treer = recall_score(y_test, y_pred_tree)\n",
    "treef1 = f1_score(y_test, y_pred_tree)\n",
    "\n",
    "# Section 4: Ensemble Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_pca, y_train)\n",
    "y_pred_rf = rf.predict(X_test_pca)\n",
    "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
    "rfp = precision_score(y_test, y_pred_rf)\n",
    "rf1 = f1_score(y_test, y_pred_rf)\n",
    "rfrr = recall_score(y_test, y_pred_rf)\n",
    "\n",
    "# Section 5: Deployment\n",
    "# A simple function for prediction\n",
    "def predict_rain(features):\n",
    "    processed_features = scaler.transform([features])\n",
    "    pca_features = pca.transform(processed_features)\n",
    "    prediction = rf.predict(pca_features)\n",
    "    return 'Yes' if prediction[0] == 1 else 'No'\n",
    "\n",
    "# Section 6: Prediction\n",
    "# Example prediction\n",
    "example_features = X_test[0]\n",
    "prediction = predict_rain(example_features)\n",
    "print(f'Prediction for the given features: {prediction}')\n",
    "\n",
    "# Section 7: Comparison among Models\n",
    "print(\"Logistic Regression Accuracy:\", log_reg_acc)\n",
    "print(\"Decision Tree Accuracy:\", tree_acc)\n",
    "print(\"Random Forest Accuracy:\", rf_acc)\n",
    "\n",
    "# Section 8: Report\n",
    "report = f\"\"\"\n",
    "Machine Learning Model Comparison:\n",
    "1. Logistic Regression: \n",
    "- Accuracy: {log_reg_acc:.3f}\n",
    "- Precision: {lrp:.3f}\n",
    "- Recall: {lrr:.3f}\n",
    "- F1 Score: {lrf1:.3f}\n",
    "2. Decision Tree:\n",
    "- Accuracy: {tree_acc:.3f}\n",
    "- Precision: {treep:.3f}\n",
    "- Recall: {treer:.3f}\n",
    "- F1 Score: {treef1:.3f}\n",
    "3. Random Forest:\n",
    "- Accuracy: {rf_acc:.3f}\n",
    "- Precision: {rfp:.3f}\n",
    "- Recall: {rfrr:.3f}\n",
    "- F1 Score: {rf1:.3f}\n",
    "\"\"\"\n",
    "print(report)\n",
    "\n",
    "# Section 9: Model Saving\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create a directory to store the model\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "# Save the trained model\n",
    "with open('./models/logreg.joblib', 'wb') as model_file:\n",
    "    joblib.dump(log_reg, model_file)\n",
    "print(\"Model saved successfully as 'logreg.joblib' in the './models' directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
